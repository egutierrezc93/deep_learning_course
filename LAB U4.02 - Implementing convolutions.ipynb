{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# LAB: Implementing convolutions"]}, {"cell_type": "code", "execution_count": 1, "metadata": {}, "outputs": [], "source": ["import init\n", "init.init(force_download=False)\n", "init.get_weblink()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["username: dl_test_student\n", "\n", "password: nada"]}, {"cell_type": "code", "execution_count": 3, "metadata": {}, "outputs": [], "source": ["from local.lib.rlxmoocapi import submit, session\n", "import inspect\n", "student = session.Session(init.endpoint).login( course_id=init.course_id, \n", "                                                session_id=\"UDEA\", \n", "                                                lab_id=\"LAB_U4.02\" )"]}, {"cell_type": "code", "execution_count": 5, "metadata": {}, "outputs": [], "source": ["import sys\n", "if 'google.colab' in sys.modules:\n", "    print (\"setting tensorflow version in colab\")\n", "    %tensorflow_version 2.x\n", "    %load_ext tensorboard\n", "import tensorflow as tf\n", "tf.__version__"]}, {"cell_type": "code", "execution_count": 6, "metadata": {}, "outputs": [], "source": ["import tensorflow as tf\n", "from time import time\n", "import pandas as pd\n", "import matplotlib.pyplot as plt\n", "import numpy as np\n", "from local.lib import mlutils\n", "%matplotlib inline"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## observe how we create a `tf.keras.Conv2D` layers and assign it some weights"]}, {"cell_type": "code", "execution_count": 7, "metadata": {}, "outputs": [], "source": ["c = tf.keras.layers.Conv2D(filters=2, kernel_size=(3,3), activation=\"sigmoid\", dtype=tf.float64)\n", "c.get_config()"]}, {"cell_type": "code", "execution_count": 44, "metadata": {}, "outputs": [], "source": ["[i.shape for i in c.weights]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["initialize its weights (filters) by forcing an evaluation "]}, {"cell_type": "code", "execution_count": 45, "metadata": {}, "outputs": [], "source": ["c(np.random.randint(10, size=(1,7,7,1)).astype(float))\n", "[i.shape for i in c.weights]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### let's set by hand some filters"]}, {"cell_type": "code", "execution_count": 46, "metadata": {}, "outputs": [], "source": ["c.weights[0].shape"]}, {"cell_type": "code", "execution_count": 47, "metadata": {}, "outputs": [], "source": ["f1 = np.r_[[[-1, 1,-1],[-1, 1,-1], [-1, 1,-1]]]\n", "f2 = np.r_[[[-1,-1,-1],[ 1, 1, 1], [-1,-1,-1]]]\n", "\n", "f = np.zeros(c.weights[0].shape)\n", "f[:,:,0,0] = f1\n", "f[:,:,0,1] = f2\n", "print (f[:,:,0,0])\n", "print (f[:,:,0,1])"]}, {"cell_type": "code", "execution_count": 48, "metadata": {}, "outputs": [], "source": ["c.set_weights([f,np.r_[0,0]]) # keep bias as [0,0]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["check they are set"]}, {"cell_type": "code", "execution_count": 49, "metadata": {}, "outputs": [], "source": ["c.weights"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## and apply the layer to some image"]}, {"cell_type": "code", "execution_count": 50, "metadata": {}, "outputs": [], "source": ["from skimage import io\n", "img = io.imread(\"local/imgs/sample_img.png\")\n", "img = img.reshape(1,*img.shape, 1)\n", "img = (img-np.min(img))/(np.max(img)-np.min(img))\n", "plt.imshow(img[0,:,:,0], cmap=plt.cm.Greys_r);"]}, {"cell_type": "markdown", "metadata": {}, "source": ["we are using **valid** padding so activations are smaller than original image"]}, {"cell_type": "code", "execution_count": 51, "metadata": {}, "outputs": [], "source": ["activations = c(img)\n", "activations.shape"]}, {"cell_type": "code", "execution_count": 52, "metadata": {}, "outputs": [], "source": ["plt.imshow(activations[0,:,:,0], cmap=plt.cm.Greys_r)"]}, {"cell_type": "code", "execution_count": 53, "metadata": {}, "outputs": [], "source": ["plt.imshow(activations[0,:,:,1], cmap=plt.cm.Greys_r)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## observe how activations pixels are computed"]}, {"cell_type": "code", "execution_count": 54, "metadata": {}, "outputs": [], "source": ["activations[0,:5,:5,1]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["three first pixels in the first row"]}, {"cell_type": "code", "execution_count": 55, "metadata": {}, "outputs": [], "source": ["sigmoid = lambda x: 1/(1+np.exp(-x))\n", "linear  = lambda x: x\n", "print (sigmoid((img[0,:3,:3,:]  * f[:,:,:,1]).sum()))\n", "print (sigmoid((img[0,:3,1:4,:] * f[:,:,:,1]).sum()))\n", "print (sigmoid((img[0,:3,2:5,:] * f[:,:,:,1]).sum()))\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["observe the shapes of filters and activations to make sense of the indices"]}, {"cell_type": "code", "execution_count": 56, "metadata": {}, "outputs": [], "source": ["img.shape, f.shape, activations.shape"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["# Step 1: Do the convolution by hand in a set of for loops\n", "\n", "## Task 1\n", "\n", "complete the following function. its parameters:\n", "\n", "- `img`: the images, an array of size [1,y,x,k], where:\n", "    - `1`: you will be receiving only one image\n", "    - `x`, `y`: the size of the image\n", "    - `k` : the number of channels\n", "    \n", "- `f`: the filters, an array of size [fy,fx,k,n], where:\n", "    - `fx`, `fy`: the size of the filters\n", "    - `k` : the number of channels (**must be the same as in images**)\n", "    - `n`: the number of filters\n", "- `activation`: the activation function to use (such as `sigmoid` or `linear` above)"]}, {"cell_type": "code", "execution_count": 22, "metadata": {}, "outputs": [], "source": ["def convolution_byhand(img, f, activation=sigmoid):\n", "    assert f.shape[2]==img.shape[3]\n", "    fy = f.shape[0]\n", "    fx = f.shape[1]\n", "    r = np.zeros( (1, img.shape[1]-fy+1, img.shape[2]-fx+1, f.shape[3] ))\n", "    ... # YOUR CODE HERE\n", "    return r"]}, {"cell_type": "code", "execution_count": 58, "metadata": {}, "outputs": [], "source": ["r = convolution_byhand(img, f)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["check your answer"]}, {"cell_type": "code", "execution_count": 59, "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(7,3))\n", "plt.subplot(121); plt.imshow(r[0,:,:,0], cmap=plt.cm.Greys_r); plt.title(\"your convolution\")\n", "plt.subplot(122); plt.imshow(activations[0,:,:,0], cmap=plt.cm.Greys_r); plt.title(\"keras convolution\")"]}, {"cell_type": "code", "execution_count": 60, "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(7,3))\n", "plt.subplot(121); plt.imshow(r[0,:,:,1], cmap=plt.cm.Greys_r); plt.title(\"your convolution\")\n", "plt.subplot(122); plt.imshow(activations[0,:,:,1], cmap=plt.cm.Greys_r); plt.title(\"keras convolution\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**Submit your solution**"]}, {"cell_type": "code", "execution_count": 65, "metadata": {}, "outputs": [], "source": ["student.submit_task(namespace=globals(), course_id=init.course_id, lab_id='LAB_U4.02', task_id='task_01')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Step 2: Do the convolution by hand in 'one shot'\n", "\n", "We will prepare images to do the convolution with one dot product operation for each filter and each image. This will use more memory but will increase performance.\n", "\n", "For instance, assume we have the following 1x8x6x1 images (only one image, one channel) and 2x3x1x2 filters (one channel, two filters)"]}, {"cell_type": "code", "execution_count": 66, "metadata": {}, "outputs": [], "source": ["img = np.r_[[9, 4, 9, 6, 7, 1, 2, 2, 8, 0, 8, 6, 8, 6, 5, 5, 1, 4, 3, 4, 4, 4,\n", "             3, 6, 5, 1, 7, 9, 1, 4, 0, 3, 1, 4, 3, 5, 1, 5, 5, 4, 9, 6, 3, 2,\n", "             8, 9, 0, 6]].reshape(1,8,6,1)\n", "f = np.r_[[6, 7, 8, 5, 2, 9, 6, 4, 9, 7, 9, 7]].reshape(2,3,1,2)\n", "print (\"images\", img.shape)\n", "print (img[0,:,:,0])\n", "print (\"--\")\n", "print (\"filters\", f.shape)\n", "print (f[:,:,0,0])\n", "print (f[:,:,0,1])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Task 2: complete the following function to prepare the images\n", "\n", "where:\n", "\n", "- `img` is the images array (assume we only have one image)\n", "- `fy` and `fx` are the filter dimensions (2,3 in the example just above)\n", "\n", "if called with `img` and `f` above you shoud get the following output\n", "\n", "    > pimg = prepare_img(img, *f.shape[:2])\n", "    > pimg\n", "    \n", "    array([[[[9., 4., 9., 2., 2., 8.],\n", "             [4., 9., 6., 2., 8., 0.],\n", "             [9., 6., 7., 8., 0., 8.],\n", "             [6., 7., 1., 0., 8., 6.]],\n", "\n", "            [[2., 2., 8., 8., 6., 5.],\n", "             [2., 8., 0., 6., 5., 5.],\n", "             [8., 0., 8., 5., 5., 1.],\n", "             [0., 8., 6., 5., 1., 4.]],\n", "\n", "            [[8., 6., 5., 3., 4., 4.],\n", "             [6., 5., 5., 4., 4., 4.],\n", "             [5., 5., 1., 4., 4., 3.],\n", "             [5., 1., 4., 4., 3., 6.]],\n", "\n", "            [[3., 4., 4., 5., 1., 7.],\n", "             [4., 4., 4., 1., 7., 9.],\n", "             [4., 4., 3., 7., 9., 1.],\n", "             [4., 3., 6., 9., 1., 4.]],\n", "\n", "            [[5., 1., 7., 0., 3., 1.],\n", "             [1., 7., 9., 3., 1., 4.],\n", "             [7., 9., 1., 1., 4., 3.],\n", "             [9., 1., 4., 4., 3., 5.]],\n", "\n", "            [[0., 3., 1., 1., 5., 5.],\n", "             [3., 1., 4., 5., 5., 4.],\n", "             [1., 4., 3., 5., 4., 9.],\n", "             [4., 3., 5., 4., 9., 6.]],\n", "\n", "            [[1., 5., 5., 3., 2., 8.],\n", "             [5., 5., 4., 2., 8., 9.],\n", "             [5., 4., 9., 8., 9., 0.],\n", "             [4., 9., 6., 9., 0., 6.]]]])\n", "             \n", "    > pimg.shape\n", "    \n", "    (1, 7, 4, 6)\n", "    \n", "    \n", "observe that:\n", "\n", "- resulting images after convolution with any filter will have size 7x4\n", "- the resulting structure `img` has at each pixel (in the 7x4 grid) a vector of six elements associated with it.\n", "- this vector is the flattened contents of 2x3x1 image fragment located at that pixel that would by multiplied element by element by any filter located at that pixel during the convolution.\n", "- the first row in `pimg` corresponds to the flattened 2x3 fragment located at the top left corner of `img`\n", "- the second row contains the 2x3 fragment after shifting one pixel to the right.\n", "- the [`np.flatten`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.flatten.html) operation will surely be useful for you."]}, {"cell_type": "code", "execution_count": 67, "metadata": {}, "outputs": [], "source": ["## Teacher\n", "def prepare_img(img, fy, fx):\n", "    r = np.zeros( (1, img.shape[1]-fy+1, img.shape[2]-fx+1, fy*fx*img.shape[3] ))\n", "    for y in range(img.shape[1]-fy):\n", "        for x in range(img.shape[2]-fx):\n", "            r[0,y,x,:] = img[0,y:y+fy,x:x+fx,:].flatten()\n", "    return r"]}, {"cell_type": "code", "execution_count": 53, "metadata": {}, "outputs": [], "source": ["def prepare_img(img, fy, fx):\n", "    r = np.zeros( (1, img.shape[1]-fy+1, img.shape[2]-fx+1, fy*fx*img.shape[3] ))\n", "    ... # YOUR CODE HERE\n", "    return r"]}, {"cell_type": "code", "execution_count": 68, "metadata": {"scrolled": true}, "outputs": [], "source": ["pimg = prepare_img(img, *f.shape[:2])\n", "print (pimg.shape)\n", "pimg"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**Submit your solution**"]}, {"cell_type": "code", "execution_count": 73, "metadata": {}, "outputs": [], "source": ["student.submit_task(namespace=globals(), course_id=init.course_id, lab_id='LAB_U4.02', task_id='task_02')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Task 3: use the prepared images to do the convolution  in a single `.dot` operation\n", "\n", "\n", "complete the following function so that:\n", "\n", "- you do the convolution of one image (`i`) and one filter (`j`) with one `.dot` operation in **one single line of code**.\n", "- you apply the corresponding activation function"]}, {"cell_type": "code", "execution_count": 76, "metadata": {}, "outputs": [], "source": ["## Teacher\n", "def oneshot_convolution(pimg, f, activation=sigmoid):\n", "    r = np.zeros((*pimg.shape[:-1], f.shape[3]))\n", "    for i in range(pimg.shape[0]):\n", "        for j in range(f.shape[3]):\n", "            r[i,:,:,j] = activation(pimg[i].dot(f[:,:,:,j].flatten()))\n", "    return r"]}, {"cell_type": "code", "execution_count": 75, "metadata": {}, "outputs": [], "source": ["def oneshot_convolution(pimg, f, activation=sigmoid):\n", "    r = np.zeros((*pimg.shape[:-1], f.shape[3]))\n", "    for i in range(pimg.shape[0]):\n", "        for j in range(f.shape[3]):\n", "            r[i,:,:,j] = ... # YOUR CODE HERE\n", "    return r"]}, {"cell_type": "markdown", "metadata": {}, "source": ["check your solution against your previous implementation"]}, {"cell_type": "code", "execution_count": 77, "metadata": {}, "outputs": [], "source": ["k1 = oneshot_convolution(pimg, f, activation=sigmoid)\n", "k2 = convolution_byhand(img, f, activation=sigmoid)\n", "np.allclose(k1, k2)"]}, {"cell_type": "code", "execution_count": 78, "metadata": {}, "outputs": [], "source": ["k1 = oneshot_convolution(pimg, f, activation=linear)\n", "k2 = convolution_byhand(img, f, activation=linear)\n", "np.allclose(k1, k2)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["check your solution against keras"]}, {"cell_type": "code", "execution_count": 79, "metadata": {}, "outputs": [], "source": ["c = tf.keras.layers.Conv2D(filters=f.shape[3], \n", "                           kernel_size=f.shape[:2], \n", "                           activation=\"linear\", dtype=tf.float64)\n", "c(img.astype(float))\n", "c.set_weights((f, np.r_[0,0]))"]}, {"cell_type": "code", "execution_count": 80, "metadata": {}, "outputs": [], "source": ["np.alltrue(c(img.astype(float)).numpy()==k2)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**Submit your solution**"]}, {"cell_type": "code", "execution_count": 85, "metadata": {}, "outputs": [], "source": ["student.submit_task(namespace=globals(), course_id=init.course_id, lab_id='LAB_U4.02', task_id='task_03')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.10"}}, "nbformat": 4, "nbformat_minor": 2}